"""
Review Pipeline Main — Pubroot

PURPOSE:
    This is the entry point and orchestrator for the entire 6-stage review
    pipeline. It is called by the GitHub Actions workflow (review.yml) and
    coordinates the stages in sequence:
    
    1. Parse & Filter — extract and validate submission fields
    2. Novelty Check — search academic databases for related work
    3. Read Linked Repo — clone and read the submitter's code
    4. Build Review Prompt — assemble the LLM prompt with all context
    5. Gemini Grounded Review — call Gemini with Google Search grounding
    6. Post Review & Decide — post comment, accept/reject, create PR
    
    It also calculates priority scores and updates contributor reputations.

CALLED BY:
    .github/workflows/review.yml — passes the issue number as a command-line
    argument. The workflow sets environment variables for API keys and repo info.

ENVIRONMENT VARIABLES:
    Required:
        GEMINI_API_KEY — Gemini API key for LLM review + grounding
        GITHUB_TOKEN — Auto-generated by GitHub Actions for API access
        GITHUB_REPOSITORY — "owner/repo" format, auto-set by Actions
    
    Optional:
        S2_API_KEY — Semantic Scholar API key for higher rate limits

USAGE:
    python review_pipeline_main.py <issue_number>
    
    Example:
    python review_pipeline_main.py 42

ERROR HANDLING:
    Each stage can fail independently. The pipeline is designed to be resilient:
    - Stage 1 failure (parse error): Post error comment, stop.
    - Stage 2 failure (API error): Continue with empty novelty context.
    - Stage 3 failure (clone error): Continue without repo context.
    - Stage 4 failure: Should never fail (pure string assembly). If it does, stop.
    - Stage 5 failure (Gemini error): Post error comment, label for retry.
    - Stage 6 failure (GitHub API error): Log and report.
"""

import json
import os
import sys
from datetime import datetime, timezone

# Import all pipeline stages
# These are in the same package (_review_agent/) so we import directly.
from stage_1_parse_and_filter import parse_and_filter_submission
from stage_2_novelty_check import check_novelty
from stage_3_read_linked_repo import read_linked_repository
from stage_4_build_review_prompt import build_review_prompt
from stage_5_gemini_grounded_review import run_gemini_grounded_review
from stage_6_post_review_and_decide import post_review_and_decide, GitHubAPI
from reputation_calculator import calculate_reputation, update_all_reputations
from priority_score_calculator import calculate_priority


def run_review_pipeline(issue_number: int) -> dict:
    """
    Run the complete 6-stage review pipeline for a given GitHub Issue.
    
    This is the main orchestration function. It reads environment variables,
    fetches the issue data, runs each stage in sequence, and returns the
    overall result.
    
    Args:
        issue_number: The GitHub Issue number to process
    
    Returns:
        dict with keys:
            - 'success' (bool): Whether the pipeline completed successfully
            - 'action' (str): 'accepted', 'rejected', 'error', 'filtered'
            - 'paper_id' (str): The assigned paper ID
            - 'score' (float or None): The review score
            - 'errors' (list[str]): Any errors encountered
    """
    
    # -----------------------------------------------------------------------
    # SETUP: Read environment variables and repo info
    # -----------------------------------------------------------------------
    
    gemini_api_key = os.environ.get("GEMINI_API_KEY", "")
    github_token = os.environ.get("GITHUB_TOKEN", "")
    github_repo = os.environ.get("GITHUB_REPOSITORY", "")  # "owner/repo"
    s2_api_key = os.environ.get("S2_API_KEY", "")
    
    if not gemini_api_key:
        print("ERROR: GEMINI_API_KEY environment variable not set")
        return {"success": False, "action": "error", "paper_id": "", "score": None,
                "errors": ["GEMINI_API_KEY not set"]}
    
    if not github_token:
        print("ERROR: GITHUB_TOKEN environment variable not set")
        return {"success": False, "action": "error", "paper_id": "", "score": None,
                "errors": ["GITHUB_TOKEN not set"]}
    
    if "/" not in github_repo:
        print(f"ERROR: Invalid GITHUB_REPOSITORY format: {github_repo}")
        return {"success": False, "action": "error", "paper_id": "", "score": None,
                "errors": [f"Invalid GITHUB_REPOSITORY: {github_repo}"]}
    
    repo_owner, repo_name = github_repo.split("/", 1)
    
    # The repo root is the current working directory when running in Actions
    # (the checkout action places us at the repo root)
    repo_root = os.environ.get("GITHUB_WORKSPACE", os.getcwd())
    
    # Generate a paper ID based on the year and issue number
    # Format: YYYY-NNN (e.g., 2026-042)
    year = datetime.now(timezone.utc).year
    paper_id = f"{year}-{issue_number:03d}"
    
    print(f"=" * 60)
    print(f"AI PEER REVIEW PIPELINE — Paper {paper_id}")
    print(f"Issue #{issue_number} in {github_repo}")
    print(f"=" * 60)
    
    # -----------------------------------------------------------------------
    # FETCH ISSUE DATA
    # -----------------------------------------------------------------------
    
    gh = GitHubAPI(repo_owner, repo_name, github_token)
    
    try:
        import requests
        issue_url = f"https://api.github.com/repos/{github_repo}/issues/{issue_number}"
        headers = {
            "Authorization": f"Bearer {github_token}",
            "Accept": "application/vnd.github+json",
        }
        resp = requests.get(issue_url, headers=headers, timeout=30)
        resp.raise_for_status()
        issue_data = resp.json()
        issue_body = issue_data.get("body", "")
        issue_author = issue_data.get("user", {}).get("login", "unknown")
    except Exception as e:
        print(f"ERROR: Failed to fetch issue #{issue_number}: {e}")
        return {"success": False, "action": "error", "paper_id": paper_id,
                "score": None, "errors": [f"Failed to fetch issue: {e}"]}
    
    print(f"\nAuthor: {issue_author}")
    print(f"Issue body length: {len(issue_body)} chars")
    
    # -----------------------------------------------------------------------
    # STAGE 0: CALCULATE PRIORITY (before the full review)
    # -----------------------------------------------------------------------
    # We calculate priority early so we can assign the label. The actual
    # review may happen later if the submission is queued. But for direct
    # triggers (issue:opened), we proceed immediately with the review.
    # -----------------------------------------------------------------------
    
    print(f"\n{'─' * 40}")
    print("STAGE 0: Priority Calculation")
    print(f"{'─' * 40}")
    
    # We need to peek at the payment code from the body before full parsing
    # This is a lightweight extraction just for priority calculation
    payment_code = None
    if "Payment Code" in issue_body:
        import re
        match = re.search(r"PAID-\w+", issue_body)
        if match:
            payment_code = match.group(0)
    
    # Parse category from the body (lightweight extraction for priority)
    # -----------------------------------------------------------------------
    # As of the taxonomy redesign (Feb 2026), categories use a two-level
    # "journal/topic" format like "ai/llm-benchmarks". We dynamically read
    # valid topics from journals.json instead of hardcoding a list.
    # The old hardcoded list (llm-benchmarks, ios-debugging, etc.) was replaced
    # because it would go stale every time journals.json changed.
    # -----------------------------------------------------------------------
    category_for_priority = ""
    if "Category" in issue_body:
        import re
        # Dynamically read valid "journal/topic" slugs from journals.json
        valid_topic_slugs = []
        try:
            with open(os.path.join(repo_root, "journals.json"), "r") as f:
                _jdata = json.load(f)
            for _jslug, _jobj in _jdata.get("journals", {}).items():
                for _tslug in _jobj.get("topics", {}).keys():
                    valid_topic_slugs.append(f"{_jslug}/{_tslug}")
        except (FileNotFoundError, json.JSONDecodeError):
            pass

        # Search the issue body for any valid topic slug
        for slug in valid_topic_slugs:
            if slug in issue_body:
                category_for_priority = slug
                break
    
    priority = calculate_priority(
        author=issue_author,
        category=category_for_priority,
        payment_code=payment_code,
        repo_root=repo_root,
    )
    
    print(f"Priority score: {priority['priority_score']}")
    print(f"Priority label: {priority['priority_label']}")
    print(f"Reputation: {priority['reputation_score']} ({priority['reputation_tier']})")
    
    # Assign the priority label
    try:
        gh.add_labels(issue_number, [priority["priority_label"]])
    except Exception as e:
        print(f"WARNING: Failed to add priority label: {e}")
    
    # -----------------------------------------------------------------------
    # STAGE 1: PARSE & FILTER
    # -----------------------------------------------------------------------
    
    print(f"\n{'─' * 40}")
    print("STAGE 1: Parse & Filter")
    print(f"{'─' * 40}")
    
    stage1_result = parse_and_filter_submission(
        issue_body=issue_body,
        repo_root=repo_root,
        issue_author=issue_author,
    )
    
    parsed = stage1_result["parsed"]
    
    print(f"Title: {parsed.get('title', '?')}")
    print(f"Category: {parsed.get('category', '?')}")
    print(f"Abstract words: {parsed.get('word_count_abstract', 0)}")
    print(f"Body words: {parsed.get('word_count_body', 0)}")
    print(f"Repo: {parsed.get('supporting_repo', 'none')}")
    print(f"Valid: {stage1_result['valid']}")
    
    if stage1_result["warnings"]:
        for w in stage1_result["warnings"]:
            print(f"  WARNING: {w}")
    
    if not stage1_result["valid"]:
        # Submission failed basic validation — post errors and stop
        error_msg = "Submission failed validation:\n" + "\n".join(
            f"- {e}" for e in stage1_result["errors"]
        )
        print(f"\nREJECTED at Stage 1: {error_msg}")
        
        gh.post_comment(issue_number, (
            f"# Submission Validation Failed\n\n"
            f"Your submission could not be processed due to the following issues:\n\n"
            + "\n".join(f"- {e}" for e in stage1_result["errors"])
            + "\n\nPlease fix these issues and resubmit."
        ))
        gh.add_labels(issue_number, ["validation-failed"])
        
        return {"success": True, "action": "filtered", "paper_id": paper_id,
                "score": None, "errors": stage1_result["errors"]}
    
    # -----------------------------------------------------------------------
    # STAGE 2: NOVELTY CHECK
    # -----------------------------------------------------------------------
    
    print(f"\n{'─' * 40}")
    print("STAGE 2: Novelty Check")
    print(f"{'─' * 40}")
    
    novelty = check_novelty(
        title=parsed["title"],
        abstract=parsed["abstract"],
        category=parsed["category"],
        repo_root=repo_root,
        s2_api_key=s2_api_key or None,
    )
    
    print(f"arXiv results: {len(novelty['arxiv_results'])}")
    print(f"S2 results: {len(novelty['s2_results'])}")
    print(f"Internal results: {len(novelty['internal_results'])}")
    print(f"Supersession: {novelty['potential_supersession'] is not None}")
    
    if novelty["errors"]:
        for e in novelty["errors"]:
            print(f"  WARNING: {e}")
    
    # -----------------------------------------------------------------------
    # STAGE 3: READ LINKED REPO
    # -----------------------------------------------------------------------
    
    print(f"\n{'─' * 40}")
    print("STAGE 3: Read Linked Repository")
    print(f"{'─' * 40}")
    
    repo_data = read_linked_repository(
        repo_url=parsed.get("supporting_repo"),
        commit_sha=parsed.get("commit_sha"),
        repo_visibility=parsed.get("repo_visibility", "no-repo"),
    )
    
    print(f"Available: {repo_data['available']}")
    print(f"Badge type: {repo_data['badge_type']}")
    print(f"Files: {repo_data['file_count']}")
    print(f"Content bytes: {repo_data['total_content_bytes']}")
    
    if repo_data["errors"]:
        for e in repo_data["errors"]:
            print(f"  WARNING: {e}")
    
    # -----------------------------------------------------------------------
    # STAGE 4: BUILD REVIEW PROMPT
    # -----------------------------------------------------------------------
    
    print(f"\n{'─' * 40}")
    print("STAGE 4: Build Review Prompt")
    print(f"{'─' * 40}")
    
    prompt = build_review_prompt(
        parsed_submission=parsed,
        novelty_results=novelty,
        repo_data=repo_data,
        repo_root=repo_root,
        paper_id=paper_id,
    )
    
    print(f"Prompt length: {len(prompt)} chars (~{len(prompt) // 4} tokens)")
    
    # -----------------------------------------------------------------------
    # STAGE 5: GEMINI GROUNDED REVIEW
    # -----------------------------------------------------------------------
    
    print(f"\n{'─' * 40}")
    print("STAGE 5: Gemini Grounded Review")
    print(f"{'─' * 40}")
    
    review_result = run_gemini_grounded_review(
        review_prompt=prompt,
        gemini_api_key=gemini_api_key,
    )
    
    if review_result["success"]:
        review = review_result["review"]
        print(f"Score: {review.get('score', '?')}/10")
        print(f"Verdict: {review.get('verdict', '?')}")
        print(f"Claims verified: {len(review.get('claims', []))}")
        grounding = review_result.get("grounding_metadata", {})
        if isinstance(grounding, dict) and grounding.get("available"):
            print(f"Search queries: {len(grounding.get('web_search_queries', []))}")
            print(f"Sources used: {len(grounding.get('sources', []))}")
    else:
        print(f"ERROR: {review_result.get('error', 'Unknown error')}")
    
    # -----------------------------------------------------------------------
    # STAGE 6: POST REVIEW & DECIDE
    # -----------------------------------------------------------------------
    
    print(f"\n{'─' * 40}")
    print("STAGE 6: Post Review & Decide")
    print(f"{'─' * 40}")
    
    result = post_review_and_decide(
        review_result=review_result,
        parsed_submission=parsed,
        novelty_results=novelty,
        repo_data=repo_data,
        paper_id=paper_id,
        issue_number=issue_number,
        repo_owner=repo_owner,
        repo_name=repo_name,
        github_token=github_token,
        repo_root=repo_root,
    )
    
    print(f"Action taken: {result['action_taken']}")
    if result.get("pr_number"):
        print(f"PR created: #{result['pr_number']}")
    
    # -----------------------------------------------------------------------
    # POST-REVIEW: Update all reputations
    # -----------------------------------------------------------------------
    
    print(f"\n{'─' * 40}")
    print("POST-REVIEW: Updating reputations")
    print(f"{'─' * 40}")
    
    try:
        updated_reps = update_all_reputations(repo_root)
        for handle, rep in updated_reps.items():
            print(f"  {handle}: {rep['reputation_score']} ({rep['reputation_tier']})")
    except Exception as e:
        print(f"WARNING: Failed to update reputations: {e}")
    
    # -----------------------------------------------------------------------
    # DONE
    # -----------------------------------------------------------------------
    
    score = None
    if review_result.get("success") and review_result.get("review"):
        score = review_result["review"].get("score")
    
    print(f"\n{'=' * 60}")
    print(f"PIPELINE COMPLETE — {result['action_taken'].upper()}")
    print(f"Paper: {paper_id}, Score: {score}")
    print(f"{'=' * 60}")
    
    return {
        "success": result["success"],
        "action": result["action_taken"],
        "paper_id": paper_id,
        "score": score,
        "errors": result.get("errors", []),
    }


# ---------------------------------------------------------------------------
# CLI ENTRY POINT
# ---------------------------------------------------------------------------
# When called from the command line (by the GitHub Action), the first argument
# is the issue number. We parse it and run the pipeline.
# ---------------------------------------------------------------------------

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python review_pipeline_main.py <issue_number>")
        sys.exit(1)
    
    try:
        issue_num = int(sys.argv[1])
    except ValueError:
        print(f"ERROR: Invalid issue number: {sys.argv[1]}")
        sys.exit(1)
    
    result = run_review_pipeline(issue_num)
    
    if not result["success"]:
        print(f"\nPipeline failed: {result.get('errors', [])}")
        sys.exit(1)
    
    sys.exit(0)
